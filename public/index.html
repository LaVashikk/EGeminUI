<!DOCTYPE html>
<html lang="en" id="oranda" class="dark">
  <head>
    <title>ellama</title>
    
      <meta property="og:url" content="https://github.com/zeozeozeo/ellama" />
    
    
      <link rel="icon" href="/favicon.ico" />
    
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
      <meta name="description" content="Friendly interface to chat with an Ollama instance." />
      <meta property="og:description" content="Friendly interface to chat with an Ollama instance." />
    
    <meta property="og:type" content="website" />
    <meta property="og:title" content="ellama" />
    
    
    
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()" />
    <link rel="stylesheet" href="/oranda-v0.6.1.css" />
    
    
  </head>
  <body>
    <div class="container">
      <div class="page-body">
        
          <div class="repo_banner">
            <a href="https://github.com/zeozeozeo/ellama">
              <div class="github-icon" aria-hidden="true"></div>
              Check out our GitHub!
            </a>
          </div>
        

        <main>
          <header>
            
            <h1 class="title">ellama</h1>
            
  <nav class="nav">
    <ul>
      <li><a href="/">Home</a></li>

      

      

      

      

      
        <li><a href="/changelog/">Changelog</a></li>
      
    </ul>
  </nav>

          </header>

          


    <h1>ü¶ô Ellama <a href="https://github.com/zeozeozeo/ellama" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/zeozeozeo/ellama.svg" alt="Ellama Stars"></a></h1>
<p>Ellama is a friendly interface to chat with a local or remote <a href="https://ollama.com/" rel="noopener noreferrer">Ollama</a> instance.</p>
<p><img src="/media/pokey.png" alt="Ellama, a friendly Ollama interface, running LLaVA"></p>
<h1>Features</h1>
<ul>
<li><strong>Chat History</strong>: create, delete and edit model settings per-chat.</li>
<li><strong>Multimodality</strong>: easily use vision capabilities of any multimodal model, such as <a href="https://ollama.com/library/llava" rel="noopener noreferrer">LLaVA</a>.</li>
<li><strong>Ollama</strong>: no need to install new inference engines, connect to a regular <a href="https://ollama.com/" rel="noopener noreferrer">Ollama</a> instance instead.</li>
<li><strong>Resource Efficient</strong>: minimal RAM and CPU usage.</li>
<li><strong>Free</strong>: no need to buy any subscriptions or servers, just fire up a local Ollama instance.</li>
</ul>
<h1>Quickstart</h1>
<ol>
<li>Download the latest Ellama release from the <a href="https://github.com/zeozeozeo/ellama/releases" rel="noopener noreferrer">Releases</a> page.
<ul>
<li>or build &amp; install from source:
<pre style="background-color:#263238;"><span style="color:#82aaff;">$ git clone https://github.com/zeozeozeo/ellama.git
</span><span style="color:#82aaff;">$ cd ellama
</span><span style="color:#82aaff;">$ cargo install</span><span style="color:#89ddff;"> --</span><span style="color:#f78c6c;">path</span><span style="color:#82aaff;"> .
</span></pre>

</li>
</ul>
</li>
<li>In the Settings ‚öôÔ∏è tab, change the Ollama host if needed (default is <code>http://127.0.0.1:11434</code>)</li>
<li>In the same tab, select a model that will be used for new chats by default. Ellama will try to select the best model on the first run.</li>
<li>Close the Settings tab, create a new chat by pressing the "‚ûï New Chat" button, and start chatting!</li>
<li>To add images, click the ‚ûï button next to the text field, drag them onto Ellama's window, or paste them from your clipboard.</li>
</ol>
<blockquote>
<p>[!NOTE]
By default, Ellama will build with the <code>tts</code> feature OFF. If you need TTS, build with <code>cargo build --features tts</code>.</p>
<p>Note that on Linux, this requires <code>libspeechd</code> (<code>libspeechd-dev</code>) to be installed. TTS is currently not enabled in release builds because of this (cross-compilation complications), see <a href="https://github.com/zeozeozeo/ellama/issues/71" rel="noopener noreferrer">https://github.com/zeozeozeo/ellama/issues/71</a></p>
</blockquote>
<h1>Gallery</h1>
<p><img src="/media/reasoning.mp4" alt="Demo of a reasoning model (Qwen3)"></p>
<p><img src="/media/funfact.png" alt="Ellama's greeting screen"></p>
<p><img src="/media/countppl.png" alt="LLaVA counting people, in Ellama"></p>
<p><img src="/media/setthings.png" alt="Ellama's settings panel"></p>
<p><img src="/media/chatedit.png" alt="Ellama's chat edit panel"></p>
<h1>Wishlist</h1>
<p>These features are not yet present in Ellama, but they would be nice to have:</p>
<ul>
<li>Support OpenAI-Compatible APIs: currently only has Ollama support</li>
<li>A "Notes" section, where you can edit and write LLM-assisted notes</li>
<li>Publish on crates.io: currently still relies on some git dependencies</li>
</ul>
<h1>License</h1>
<p>Unlicense OR MIT OR Apache-2.0</p>



        </main>
      </div>

      <footer>
        
          <a href="https://github.com/zeozeozeo/ellama"><div class="github-icon" aria-hidden="true"></div></a>
        
        <span>
          ellama, MIT OR Apache-2.0
        </span>
      </footer>
    </div>

    
    

    


  </body>
</html>